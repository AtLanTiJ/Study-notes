# 爬虫

## 一、简介

- 搜索引擎：百度、谷歌、企业内部的知识库，某些项目专项数据爬取、专业的数据爬取
- 互联网：公网（不需要授权的情况下接可以浏览的内容，搜索引擎的重点），深网（需要授权才能够使用的内容），暗网（非正式渠道，无法使用常规手段访问）
- 爬取互联网的公开信息，但是正常情况下，也需要遵守一个规则：robots协议

## 二、基本原理

- 所有网页均是HTML，HTML首先是一个大的字符串，可以按照字符串处理的额方式对响应进行解析处理。其次，HTML本身也是一门标记语言，与XML是同宗同源，所以可以使用DOM对其文本进行处理
- 所有的爬虫，核心都是基于超链接，进而实现了网站和网页的跳转。
- 如果要实现一个整站爬取程序，首先要收集到站内所有网址，并且将重复网址去除，开始爬取内容并保存在本地或数据库中，进而实现后续目标

## 三、基于正则表达式的爬虫

- 访问目标网站

- 解析所有超链接

  ```python
  resp = requests.get('http://xxxxxx.com/')
  links = re.findall('<a href="(.+?)"',resp.text)
  for link in links:
      # 根据页面特性，将一些无用的超链接进行排除
      if 'artileid' in link:
          continue
      if link.startswith('#'):
      	continue
      # 对超链接进行处理，凭借出完整的URL地址
      if link.startswith('/'):
          link = 'http://xxxxxx.com' + link
      # 将爬取内容保存到本地
      resp = requests.get(link)
      filename = lin.split('/')[-1] + time.strftime("_Y%m%d_%H%M%S") + '.html'
      with open(f'/xxx/page/{filename}',mode='w') as file:
          file.write(resp.text)
  ```

## 四、基于BeautifulSoup的爬虫

### 1.简介

- BeautifulSoup是一个可以从HTML或XML文件中提取数据的python库；它能够通过转换器实现惯用的文档导航、查找、修改文档的方式。
- BeautifulSoup是一个基于re开发的解析库，可以提供一些强大的解析功能；使用BeautifulSoup能够提高提取数据的效率与爬虫开发效率。
- BS基于DOM结构进行页面内容解析，当开始解析时，会将整个页面的DOM树保存到内存中，进而实现查找。

### 2.代码实现

```python
import requests
from bs4 import BeautifulSoup

resp = requests.get('http://xxxx.com/')

# 初始化解析器
_html = BeautifulSoup(resp.text,'lxml')
# 查找页面元素(根据标签层次进行查找)
print(_html.head.title.string)          # 获取页面标题的文本内容
print(_html.div)                        # 查找页面中的第一个div元素
print(_html.div.div.div)
```

- 查找页面元素的通用方法：

  - find_all:根据标签、属性、Xpath等进行查找

    ```python
    # 查找页面所有超链接
    links = _html.find_all('a')
    for link in links:
        print(link['href'])
        
    # 查找页面所有图片
    images = _html.find_all('img')
    for image in images:
        print(image['src'])
        
    # 根据id 或class等属性查找
    keyword = _html.find(id='keyword')
    print(keyword)
    
    titles = _html.find_all(class_='title')
    for title in titles:
    #	print(title)
    #   print(title.find('a'))
    	print(title.string)
    ```

    

  - select:css选择器，div、#id、.class

    ```python
    # 找标题
    title = _html.select('div.title')
    for title in titles:
        print(title.string)
        
    # 找id
    keyeord = _html.select('#keyword')
    print(keyword[0]['placeholder'])
    ```

### 3.参考资料 

- [Beautiful Soup 4.4.0 文档 — Beautiful Soup 4.2.0 中文 文档](https://beautifulsoup.readthedocs.io/zh-cn/v4.4.0/)
- [python解析xml之lxml - 编程浪子Yiutto - 博客园 (cnblogs.com)](https://www.cnblogs.com/Yiutto/p/5387021.html)

